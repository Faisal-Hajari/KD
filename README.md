# KD
## Area for research: 
1. Data-free KD 
2. Multi-modality KD 
3. KD for generative models
4. KD for segmentation (tasks other than classification are tackled less)
## Papers from [CVPR2023](https://cvpr2023.thecvf.com/Conferences/2023/AcceptedPapers): 
20 papers (might missed some papers)
| Title      | 
| ----------- |
|[Constructing Deep Spiking Neural Networks from Artificial Neural Networks with Knowledge Distillation](https://arxiv.org/abs/2304.05627)|
|[Masked Autoencoders Enable Efficient Knowledge Distillers](https://arxiv.org/abs/2208.12256)|
|[Multi-Mode Online Knowledge Distillation for Self-Supervised Visual Representation Learning](https://arxiv.org/abs/2304.06461)  |
|[StructVPR: Distill Structural Knowledge with Weighting Samples for Visual Place Recognition](https://arxiv.org/abs/2212.00937)  |
|[PointDistiller: Structured Knowledge Distillation Towards Efficient and Compact 3D Detection](https://arxiv.org/abs/2205.11098)  |
|[KD-GAN: Data Limited Image Generation via Knowledge Distillation](https://arxiv.org/abs/2303.17158)  |
|[Generalization Matters: Loss Minima Flattening via Parameter Hybridization for Efficient Online Knowledge Distillation](https://arxiv.org/abs/2303.14666)  |
|[Knowledge Distillation for 6D Pose Estimation by Aligning Distributions of Local Predictions](https://arxiv.org/abs/2205.14971)  |
|[Rethinking Feature-based Knowledge Distillation for Face Recognition](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Rethinking_Feature-Based_Knowledge_Distillation_for_Face_Recognition_CVPR_2023_paper.pdf) |
|[Supervised Masked Knowledge Distillation for Few-Shot Transformers ](https://arxiv.org/abs/2303.15466)  |
|[Data-Free Knowledge Distillation via Feature Exchange and Activation Region Constraint]()  - unavilabel  |
|[Class Attention Transfer Based Knowledge Distillation](https://arxiv.org/pdf/2304.12777.pdf)  |
|[A Unified Knowledge Distillation Framework for Deep Directed Graphical Models](https://openreview.net/pdf?id=IxCAF8IMatf)  |
|[X^3KD: Knowledge Distillation Across Modalities, Tasks and Stages for Multi-Camera 3D Object Detection](https://arxiv.org/abs/2303.02203)  |
|[UniDistill: A Universal Cross-Modality Knowledge Distillation Framework for 3D Object Detection in Birdâ€™s-Eye View](https://arxiv.org/pdf/2303.15083.pdf)  |
|[Learning to Retain while Acquiring: Combating Distribution-Shift in Adversarial Data-Free Knowledge Distillation](https://arxiv.org/pdf/2302.14290)  |
|[Incrementer: Transformer for Class-Incremental Semantic Segmentation with Knowledge Distillation Focusing on Old Class]()  - unavilabel  |
|[MobileVOS: Real-Time Video Object Segmentation Contrastive Learning meets Knowledge Distillation](https://arxiv.org/pdf/2303.07815)  |
|[itKD: Interchange Transfer-based Knowledge Distillation for 3D Object Detection](https://arxiv.org/pdf/2205.15531)  |
|[Probabilistic Knowledge Distillation for Face Ensembles]()  - unavilabel  |
|[DaFKD: Domain-aware Federated Knowledge Distillation](https://www.preprints.org/manuscript/202303.0432/download/final_file)  |
## Papers from [CVPR2022](https://openaccess.thecvf.com/CVPR2022?day=all): 
21 papers (might missed some papers)
 | Title      | 
| ----------- |
|[Focal and Global Knowledge Distillation for Detectors](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Focal_and_Global_Knowledge_Distillation_for_Detectors_CVPR_2022_paper.pdf)|
|[Wavelet Knowledge Distillation: Towards Efficient Image-to-Image Translation](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Wavelet_Knowledge_Distillation_Towards_Efficient_Image-to-Image_Translation_CVPR_2022_paper.pdf)|
|[Performance-Aware Mutual Knowledge Distillation for Improving Neural Architecture Search](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Performance-Aware_Mutual_Knowledge_Distillation_for_Improving_Neural_Architecture_Search_CVPR_2022_paper.pdf)|
|[Open-Vocabulary One-Stage Detection With Hierarchical Visual-Language Knowledge Distillation](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Open-Vocabulary_One-Stage_Detection_With_Hierarchical_Visual-Language_Knowledge_Distillation_CVPR_2022_paper.pdf)|
|[DearKD: Data-Efficient Early Knowledge Distillation for Vision Transformers](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_DearKD_Data-Efficient_Early_Knowledge_Distillation_for_Vision_Transformers_CVPR_2022_paper.pdf)|
|[Knowledge Distillation via the Target-Aware Transformer](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Knowledge_Distillation_via_the_Target-Aware_Transformer_CVPR_2022_paper.pdf)|
|[How Many Observations Are Enough? Knowledge Distillation for Trajectory Forecasting](https://openaccess.thecvf.com/content/CVPR2022/papers/Monti_How_Many_Observations_Are_Enough_Knowledge_Distillation_for_Trajectory_Forecasting_CVPR_2022_paper.pdf)|
|[Evaluation-Oriented Knowledge Distillation for Deep Face Recognition](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Evaluation-Oriented_Knowledge_Distillation_for_Deep_Face_Recognition_CVPR_2022_paper.pdf)|
|[Class-Incremental Learning by Knowledge Distillation With Adaptive Feature Consolidation](https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Class-Incremental_Learning_by_Knowledge_Distillation_With_Adaptive_Feature_Consolidation_CVPR_2022_paper.pdf)|
|[Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation](https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_Point-to-Voxel_Knowledge_Distillation_for_LiDAR_Semantic_Segmentation_CVPR_2022_paper.pdf)|
|[Knowledge Distillation As Efficient Pre-Training: Faster Convergence, Higher Data-Efficiency, and Better Transferability](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Knowledge_Distillation_As_Efficient_Pre-Training_Faster_Convergence_Higher_Data-Efficiency_and_CVPR_2022_paper.pdf)|
|[Knowledge Distillation With the Reused Teacher Classifier](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Knowledge_Distillation_With_the_Reused_Teacher_Classifier_CVPR_2022_paper.pdf)|
|[Knowledge Distillation: A Good Teacher Is Patient and Consistent](https://openaccess.thecvf.com/content/CVPR2022/papers/Beyer_Knowledge_Distillation_A_Good_Teacher_Is_Patient_and_Consistent_CVPR_2022_paper.pdf)|
|[PCA-Based Knowledge Distillation Towards Lightweight and Content-Style Balanced Photorealistic Style Transfer Models](https://openaccess.thecvf.com/content/CVPR2022/papers/Chiu_PCA-Based_Knowledge_Distillation_Towards_Lightweight_and_Content-Style_Balanced_Photorealistic_Style_CVPR_2022_paper.pdf)|
|[TeachAugment: Data Augmentation Optimization Using Teacher Knowledge](https://openaccess.thecvf.com/content/CVPR2022/papers/Suzuki_TeachAugment_Data_Augmentation_Optimization_Using_Teacher_Knowledge_CVPR_2022_paper.pdf)|
|[Class Similarity Weighted Knowledge Distillation for Continual Semantic Segmentation](https://openaccess.thecvf.com/content/CVPR2022/papers/Phan_Class_Similarity_Weighted_Knowledge_Distillation_for_Continual_Semantic_Segmentation_CVPR_2022_paper.pdf)|
|[Cross-Image Relational Knowledge Distillation for Semantic Segmentation](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Cross-Image_Relational_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.pdf)|
|[Decoupled Knowledge Distillation](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Decoupled_Knowledge_Distillation_CVPR_2022_paper.pdf)|
|[Multi-Objective Diverse Human Motion Prediction With Knowledge Distillation](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Multi-Objective_Diverse_Human_Motion_Prediction_With_Knowledge_Distillation_CVPR_2022_paper.pdf)|
|[Structural and Statistical Texture Knowledge Distillation for Semantic Segmentation](https://openaccess.thecvf.com/content/CVPR2022/papers/Ji_Structural_and_Statistical_Texture_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.pdf)|
|[Fine-Tuning Global Model via Data-Free Knowledge Distillation for Non-IID Federated Learning](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Fine-Tuning_Global_Model_via_Data-Free_Knowledge_Distillation_for_Non-IID_Federated_CVPR_2022_paper.pdf)|

# Multi-Model
## Area for research: 
1. CLIP in point-cloud/3D. 
2. Open-Vocabulary Object Detection (OVD)
3. effecent CLIP training (better use of computation or data)
## Papers from [CVPR2023](https://cvpr2023.thecvf.com/Conferences/2023/AcceptedPapers): 
__ papers (might missed some papers)
| Title      | 
| ----------- |
|[Local 3D Editing via 3D Distillation of CLIP Knowledge - unavilabel]()|
|[AttriCLIP: A Non-Incremental Learner for Incremental Knowledge Learning - unavilabel]()|
|[ShapeClipper: Scalable 3D Shape Learning from Single-View Images via Geometric and CLIP-based Consistency](https://zixuanh.com/projects/shapeclipper.html)|
|[CLIP2: Contrastive Language-Image-Point Pretraining From Real-World Point Cloud Data](https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_CLIP2_Contrastive_Language-Image-Point_Pretraining_From_Real-World_Point_Cloud_Data_CVPR_2023_paper.pdf)|
|[DetCLIPv2: Scalable Open-Vocabulary Object Detection Pre-training via Word-Region Alignment](https://arxiv.org/abs/2304.04514)|
|[DisCo-CLIP: A Distributed Contrastive Loss for Memory Efficient CLIP Training](https://arxiv.org/abs/2304.08480)|
|[Fine-Tuned CLIP Models Are Efficient Video Learners](https://openaccess.thecvf.com/content/CVPR2023/papers/Rasheed_Fine-Tuned_CLIP_Models_Are_Efficient_Video_Learners_CVPR_2023_paper.pdf)|
|[Vita-CLIP: Video and text adaptive CLIP via Multimodal Prompting](https://arxiv.org/abs/2304.03307)|
|[CLIP Is Also an Efficient Segmenter: A Text-Driven Approach for Weakly Supervised Semantic Segmentation](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_CLIP_Is_Also_an_Efficient_Segmenter_A_Text-Driven_Approach_for_CVPR_2023_paper.pdf)|
|[HOICLIP: Efficient Knowledge Transfer for HOI Detection with Vision-Language Models](https://arxiv.org/abs/2303.15786)|
|[Learning to Name Classes for Vision and Language Models](https://openaccess.thecvf.com/content/CVPR2023/papers/Parisot_Learning_To_Name_Classes_for_Vision_and_Language_Models_CVPR_2023_paper.pdf)|
|[Scaling Language-Image Pre-training via Masking](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Scaling_Language-Image_Pre-Training_via_Masking_CVPR_2023_paper.pdf)|
|[CLIP2Protect: Protecting Facial Privacy using Text-Guided Makeup via
Adversarial Latent Search](https://openaccess.thecvf.com/content/CVPR2023/papers/Shamshad_CLIP2Protect_Protecting_Facial_Privacy_Using_Text-Guided_Makeup_via_Adversarial_Latent_CVPR_2023_paper.pdf)|
|[WinCLIP: Zero-/Few-Shot Anomaly Classification and Segmentation](https://openaccess.thecvf.com/content/CVPR2023/papers/Jeong_WinCLIP_Zero-Few-Shot_Anomaly_Classification_and_Segmentation_CVPR_2023_paper.pdf)|
|[CLIP-Sculptor: Zero-Shot Generation of High-Fidelity and Diverse Shapes From Natural Language](https://openaccess.thecvf.com/content/CVPR2023/papers/Sanghi_CLIP-Sculptor_Zero-Shot_Generation_of_High-Fidelity_and_Diverse_Shapes_From_Natural_CVPR_2023_paper.pdf)|
|[Multimodality Helps Unimodality: Cross-Modal Few-Shot Learning with Multimodal Models](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Multimodality_Helps_Unimodality_Cross-Modal_Few-Shot_Learning_With_Multimodal_Models_CVPR_2023_paper.pdf)|
|[CrowdCLIP: Unsupervised Crowd Counting via Vision-Language Model ](https://openaccess.thecvf.com/content/CVPR2023/papers/Liang_CrowdCLIP_Unsupervised_Crowd_Counting_via_Vision-Language_Model_CVPR_2023_paper.pdf)|
|[]()|
|[]()|
|[]()|
|[]()|
|[]()|
|[]()|
|[]()|
|[]()|
|[]()|
|[]()|
|[]()|
|[]()|
|[]()|
|[]()|
|[]()|
