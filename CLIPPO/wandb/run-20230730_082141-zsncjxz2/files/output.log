Data loaded: there are 1000000 images.
model and optimizer are ready.
Starting clippo training !
/home/temp/miniconda3/envs/stanford_env/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.
  warnings.warn(
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbe78f0d940>
Traceback (most recent call last):
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1466, in __del__
    self._shutdown_workers()
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1411, in _shutdown_workers
    self._worker_result_queue.put((None, None))
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/multiprocessing/queues.py", line 94, in put
    self._start_thread()
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/multiprocessing/queues.py", line 177, in _start_thread
    self._thread.start()
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/threading.py", line 904, in start
    self._started.wait()
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/threading.py", line 581, in wait
    signaled = self._cond.wait(timeout)
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt:
Traceback (most recent call last):
  File "/home/temp/Desktop/KD/CLIPPO/train.py", line 164, in <module>
    main(args)
  File "/home/temp/Desktop/KD/CLIPPO/train.py", line 124, in main
    loss = train_one_epoch(clippo, data_loader, optimizer,
  File "/home/temp/Desktop/KD/CLIPPO/train.py", line 54, in train_one_epoch
    fp16_scaler.step(optimizer)
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py", line 341, in step
    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py", line 288, in _maybe_opt_step
    retval = optimizer.step(*args, **kwargs)
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/site-packages/torch/optim/optimizer.py", line 140, in wrapper
    out = func(*args, **kwargs)
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/site-packages/torch/optim/adamw.py", line 162, in step
    adamw(params_with_grad,
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/site-packages/torch/optim/adamw.py", line 219, in adamw
    func(params,
  File "/home/temp/miniconda3/envs/stanford_env/lib/python3.9/site-packages/torch/optim/adamw.py", line 316, in _single_tensor_adamw
    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
KeyboardInterrupt